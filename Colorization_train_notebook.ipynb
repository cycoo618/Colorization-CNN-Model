{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, MaxPool2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, xyz2lab\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import h5py\n",
    "from skimage import io,color\n",
    "from os import walk\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert RGB images to LAB using CIELAB, then return input X (L), target Y (A. B)\n",
    "def rgbtolab_batch(path,row,column):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    j=1\n",
    "    for (dirpath,dirnames,filenames) in walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\".jpg\")==True:\n",
    "                # Get images\n",
    "                image = img_to_array(load_img(dirpath+filename))\n",
    "                image = np.array(image, dtype=float)\n",
    "                if len(image[0]) == column or len(image) == row:\n",
    "                    #print(j)\n",
    "                    x = rgb2lab(1.0/255*image)[:,:,0]\n",
    "                    y = rgb2lab(1.0/255*image)[:,:,1:]\n",
    "                    y /= 128 #scale y\n",
    "                    X.append(x)\n",
    "                    Y.append(y)\n",
    "                    j +=1\n",
    "    return X,Y\n",
    "\n",
    "def labtorgb_batch(l,a,b):\n",
    "    rgb=[]\n",
    "    for i in range(len(l)):\n",
    "        lab=np.dstack([l[i],a[i],b[i]])\n",
    "        img=color.lab2rgb(lab)\n",
    "        rgb.append(img)\n",
    "\n",
    "    return rgb\n",
    "\n",
    "def showgray(path):\n",
    "    for (dirpath,dirnames,filenames) in walk(path):\n",
    "        for filename in filenames:\n",
    "            rgb=io.imread(dirpath+filename,plugin='matplotlib')\n",
    "            lab=color.rgb2lab(rgb)\n",
    "            lab_copy=lab.copy()\n",
    "            lab_copy[:,:,1]=0\n",
    "            lab_copy[:,:,2]=0\n",
    "            grey=color.lab2rgb(lab_copy)\n",
    "            #plt.imsave(img[:-4]+'_gray.jpg',grey)\n",
    "            plt.imshow(grey)\n",
    "            plt.show()\n",
    "\n",
    "def showRGB(img_list):\n",
    "    for i in img_list:\n",
    "        plt.imshow(i)\n",
    "        plt.show()\n",
    "\n",
    "def savePredict(img_list):\n",
    "    for i in range(len(img_list)):\n",
    "        plt.imsave((\"{}{}_predict{}.jpg\").format(predict_path,i),datetime.today().strftime('%y%m%d-%h%m%s'),img_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Some Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define column and row to find related folder\n",
    "column=80\n",
    "row=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training path: images/60-80/train/\n",
      "Testing path: images/60-80/test/\n",
      "Predict/Colorized path: images/60-80/predict/\n",
      "Model saved path: images/60-80/model/\n"
     ]
    }
   ],
   "source": [
    "###Define Paths\n",
    "path=\"images/\"\n",
    "folder = str(row)+\"-\"+str(column)\n",
    "train_path=path+folder+\"/train/\"\n",
    "test_path=path+folder+\"/test/\"\n",
    "predict_path=path+folder+\"/predict/\"\n",
    "model_path=path+folder+\"/model/\"\n",
    "\n",
    "print(\"Training path: {}\".format(train_path))\n",
    "print(\"Testing path: {}\".format(test_path))\n",
    "print(\"Predict/Colorized path: {}\".format(predict_path))\n",
    "print(\"Model saved path: {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Processing and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images are loaded for training and validation.\n",
      "6 images are loaded for testing.\n",
      "Images have a size of: 60 * 80\n"
     ]
    }
   ],
   "source": [
    "# Read training dataset\n",
    "X,Y = rgbtolab_batch(train_path,row,column)\n",
    "\n",
    "# Read testing dataset\n",
    "X_test,Y_test = rgbtolab_batch(test_path,row,column)\n",
    "\n",
    "# Define some parameters for sizes\n",
    "n_sample=len(X)\n",
    "n_test=len(X_test)\n",
    "size=column*row\n",
    "\n",
    "# Pre-process the data by reshaping\n",
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "X = X.reshape(n_sample, row, column, 1)\n",
    "Y = Y.reshape(n_sample, row, column, 2)\n",
    "\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n",
    "X_test = X_test.reshape(n_test, row, column, 1)\n",
    "Y_test = Y_test.reshape(n_test, row, column, 2)\n",
    "\n",
    "print(\"{} images are loaded for training and validation.\".format(n_sample))\n",
    "print(\"{} images are loaded for testing.\".format(n_test))\n",
    "print(\"Images have a size of: {} * {}\".format(row, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some Hyperparameters\n",
    "n=6 #kernal size\n",
    "epoch=50 #epoch number\n",
    "validation=0.005 #validation split\n",
    "batch=10 #batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build Model and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (n, n), activation='relu', padding='same', input_shape=(row, column, 1)))\n",
    "model.add(Conv2D(16, (n, n), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (n, n), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (n, n), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(64, (n, n), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (n, n), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(128, (n, n), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (n, n), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (n, n), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (n, n), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (n, n), activation='tanh', padding='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on a validation split of 0.005, 50 epochs, batch size of 10\n",
      "Train on 995 samples, validate on 5 samples\n",
      "Epoch 1/50\n",
      "995/995 [==============================] - 429s 431ms/step - loss: 0.0128 - acc: 0.5673 - val_loss: 0.0080 - val_acc: 0.6983\n",
      "Epoch 2/50\n",
      "995/995 [==============================] - 444s 446ms/step - loss: 0.0128 - acc: 0.5876 - val_loss: 0.0081 - val_acc: 0.6983\n",
      "Epoch 3/50\n",
      "995/995 [==============================] - 443s 445ms/step - loss: 0.0127 - acc: 0.5876 - val_loss: 0.0081 - val_acc: 0.6983\n",
      "Epoch 4/50\n",
      "995/995 [==============================] - 394s 396ms/step - loss: 0.0127 - acc: 0.5876 - val_loss: 0.0081 - val_acc: 0.6983\n",
      "Epoch 5/50\n",
      "995/995 [==============================] - 446s 448ms/step - loss: 0.0127 - acc: 0.5876 - val_loss: 0.0081 - val_acc: 0.6983\n",
      "Epoch 6/50\n",
      "530/995 [==============>...............] - ETA: 3:33 - loss: 0.0126 - acc: 0.5852"
     ]
    }
   ],
   "source": [
    "# Fit model (training)\n",
    "print(\"Training model on a validation split of {}, {} epochs, batch size of {}\".format(validation, epoch, batch))\n",
    "model.fit(X, Y, validation_split=validation, epochs=epoch, batch_size=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on test batch\n",
    "model.evaluate(X_test,Y_test,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict RGB\n",
    "Y_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process output data and show/save colorized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the predicted data by reshaping to displayable RGB\n",
    "Y_predict *=128\n",
    "Y_a=Y_predict[:,:,:,0].reshape(n_test,row,column,1)\n",
    "Y_b=Y_predict[:,:,:,1].reshape(n_test,row,column,1)\n",
    "Y_ori_a=Y_test[:,:,:,0].reshape(n_test,row,column,1)*128\n",
    "Y_ori_b=Y_test[:,:,:,1].reshape(n_test,row,column,1)*128\n",
    "rgb_list=labtorgb_batch(X_test,Y_a,Y_b)\n",
    "rgb_original=labtorgb_batch(X_test,Y_ori_a,Y_ori_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showRGB(rgb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showRGB(rgb_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePredict(rgb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grey_original=showgray(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Model and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json=model.to_json()\n",
    "\n",
    "with open(\"{}model_{}.json\".format(predict_path,datetime.today().strftime('%y%m%d-%h%m%s')),\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"{}model_{}.h5\".format(predict_path,datetime.today().strftime('%y%m%d-%h%m%s')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
